{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72594d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensoflow.keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c52d624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (10000, 784) 784\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1337)\n",
    "\n",
    "#-- Cargar sólo las imágenes sin las etiquetas ---\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "input_dim = 28*28\n",
    "x_train = np.reshape(x_train, [-1, input_dim])/255.0\n",
    "x_test = np.reshape(x_test,   [-1, input_dim])/255.0\n",
    "\n",
    "print(x_train.shape,x_test.shape,input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b3274f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "latent_vector (Dense)        (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "decoder_output (Dense)       (None, 784)               101136    \n",
      "=================================================================\n",
      "Total params: 222,384\n",
      "Trainable params: 222,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # This is the size of our encoded representations\n",
    "# encoding_dim = 32  # 32 flotantes -> factor de compresion 24.5, asumiendo una entrada de 28x28=784\n",
    "\n",
    "# ##-------- ENCODER ---------------\n",
    "# encoder_input = Input(shape=(input_dim,), name='encoder_input')\n",
    "# code = Dense(128, activation='relu', name='codDense01')(encoder_input)\n",
    "# code = Dense(64, activation='relu', name='codDense02')(code)\n",
    "# code = Dense(encoding_dim, name='latent_vector')(code)\n",
    "# encoder = Model(encoder_input, code, name='encoder')\n",
    "\n",
    "# ##------- DECODER -----------\n",
    "# latent_input = Input(shape=(encoding_dim,), name='decoder_input')\n",
    "# decoded_image = Dense(64, activation='relu')(latent_input)\n",
    "# decoded_image = Dense(128, activation='relu')(decoded_image)\n",
    "# decoded_image = Dense(input_dim,activation=\"sigmoid\",name='decoder_output')(decoded_image)\n",
    "# decoder = Model(latent_input, decoded_image, name='decoder')\n",
    "\n",
    "# # Este modelo mapea una entrada en su reconstrucción\n",
    "# autoencoder = Model(encoder_input, decoder(encoder(encoder_input)), name='autoencoder')\n",
    "# print(autoencoder.summary()) \n",
    "# print(encoder.summary()) \n",
    "\n",
    "input_img = layers.Input(shape=(784,), name='encoder_input')\n",
    "encoded = layers.Dense(128, activation='relu')(input_img)\n",
    "encoded = layers.Dense(64, activation='relu')(encoded)\n",
    "encoded = layers.Dense(32, activation='relu', name='latent_vector')(encoded)\n",
    "\n",
    "decoded = layers.Dense(64, activation='relu')(encoded)\n",
    "decoded = layers.Dense(128, activation='relu')(decoded)\n",
    "decoded = layers.Dense(784, activation='sigmoid',name='decoder_output')(decoded)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "print(autoencoder.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "159995c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 0.2472 - val_loss: 0.1683\n",
      "Epoch 2/100\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.1512 - val_loss: 0.1391\n",
      "Epoch 3/100\n",
      "235/235 [==============================] - 4s 15ms/step - loss: 0.1324 - val_loss: 0.1261\n",
      "Epoch 4/100\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.1226 - val_loss: 0.1177\n",
      "Epoch 5/100\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.1162 - val_loss: 0.1128\n",
      "Epoch 6/100\n",
      "235/235 [==============================] - 3s 15ms/step - loss: 0.1115 - val_loss: 0.1082\n",
      "Epoch 7/100\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 0.1082 - val_loss: 0.1060\n",
      "Epoch 8/100\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 0.1058 - val_loss: 0.1037\n",
      "Epoch 9/100\n",
      "235/235 [==============================] - 4s 15ms/step - loss: 0.1037 - val_loss: 0.1014\n",
      "Epoch 10/100\n",
      "235/235 [==============================] - 4s 15ms/step - loss: 0.1017 - val_loss: 0.0998\n",
      "Epoch 11/100\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.0998 - val_loss: 0.0978\n",
      "Epoch 12/100\n",
      "235/235 [==============================] - 4s 15ms/step - loss: 0.0983 - val_loss: 0.0968\n",
      "Epoch 13/100\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 0.0972 - val_loss: 0.0960\n",
      "Epoch 14/100\n",
      "235/235 [==============================] - 4s 15ms/step - loss: 0.0961 - val_loss: 0.0946\n",
      "Epoch 15/100\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 0.0953 - val_loss: 0.0939\n",
      "Epoch 16/100\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0946 - val_loss: 0.0930\n",
      "Epoch 17/100\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0939 - val_loss: 0.0926\n",
      "Epoch 18/100\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0933 - val_loss: 0.0921\n",
      "Epoch 19/100\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 0.0927 - val_loss: 0.0917\n",
      "Epoch 20/100\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0921 - val_loss: 0.0910\n",
      "Epoch 21/100\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0916 - val_loss: 0.0903\n",
      "Epoch 22/100\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0910 - val_loss: 0.0903\n",
      "Epoch 23/100\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0906 - val_loss: 0.0896\n",
      "Epoch 24/100\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0902 - val_loss: 0.0893\n",
      "Epoch 25/100\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 0.0897 - val_loss: 0.0889\n",
      "Epoch 26/100\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 0.0894 - val_loss: 0.0888\n",
      "Epoch 27/100\n",
      "235/235 [==============================] - 3s 15ms/step - loss: 0.0891 - val_loss: 0.0881\n",
      "Epoch 28/100\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0887 - val_loss: 0.0878\n",
      "Epoch 29/100\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0884 - val_loss: 0.0874\n",
      "Epoch 30/100\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0881 - val_loss: 0.0873\n",
      "Epoch 31/100\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 0.0877 - val_loss: 0.0871\n",
      "Epoch 32/100\n",
      "235/235 [==============================] - 3s 15ms/step - loss: 0.0874 - val_loss: 0.0866\n",
      "Epoch 33/100\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 0.0871 - val_loss: 0.0866\n",
      "Epoch 34/100\n",
      "235/235 [==============================] - 3s 15ms/step - loss: 0.0869 - val_loss: 0.0861\n",
      "Epoch 35/100\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0866 - val_loss: 0.0859\n",
      "Epoch 36/100\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0863 - val_loss: 0.0856\n",
      "Epoch 37/100\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0861 - val_loss: 0.0854\n",
      "Epoch 38/100\n",
      "235/235 [==============================] - 4s 15ms/step - loss: 0.0857 - val_loss: 0.0850\n",
      "Epoch 39/100\n",
      "235/235 [==============================] - 4s 15ms/step - loss: 0.0855 - val_loss: 0.0851\n",
      "Epoch 40/100\n",
      "235/235 [==============================] - 4s 15ms/step - loss: 0.0853 - val_loss: 0.0850\n",
      "Epoch 41/100\n",
      "235/235 [==============================] - 3s 15ms/step - loss: 0.0850 - val_loss: 0.0848\n",
      "Epoch 42/100\n",
      "235/235 [==============================] - 3s 15ms/step - loss: 0.0849 - val_loss: 0.0842\n",
      "Epoch 43/100\n",
      "235/235 [==============================] - 4s 19ms/step - loss: 0.0847 - val_loss: 0.0841\n",
      "Epoch 44/100\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.0844 - val_loss: 0.0841\n",
      "Epoch 45/100\n",
      "235/235 [==============================] - 4s 15ms/step - loss: 0.0843 - val_loss: 0.0836\n",
      "Epoch 46/100\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0841 - val_loss: 0.0837\n",
      "Epoch 47/100\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0839 - val_loss: 0.0834\n",
      "Epoch 48/100\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0838 - val_loss: 0.0834\n",
      "Epoch 49/100\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0836 - val_loss: 0.0832\n",
      "Epoch 50/100\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0835 - val_loss: 0.0829\n",
      "Epoch 51/100\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0833 - val_loss: 0.0831\n",
      "Epoch 52/100\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0832 - val_loss: 0.0825\n",
      "Epoch 53/100\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0830 - val_loss: 0.0827\n",
      "Epoch 54/100\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0829 - val_loss: 0.0826\n",
      "Epoch 55/100\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 0.0827 - val_loss: 0.0823\n",
      "Epoch 56/100\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 0.0826 - val_loss: 0.0823\n",
      "Epoch 57/100\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0825 - val_loss: 0.0822\n",
      "Epoch 58/100\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0824 - val_loss: 0.0820\n",
      "Epoch 59/100\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.0822 - val_loss: 0.0821\n",
      "Epoch 60/100\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 0.0821 - val_loss: 0.0817\n",
      "Epoch 61/100\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 0.0820 - val_loss: 0.0816\n",
      "Epoch 62/100\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 0.0819 - val_loss: 0.0820\n",
      "Epoch 63/100\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 0.0818 - val_loss: 0.0813\n",
      "Epoch 64/100\n",
      "235/235 [==============================] - 4s 15ms/step - loss: 0.0816 - val_loss: 0.0812\n",
      "Epoch 65/100\n",
      "235/235 [==============================] - 4s 15ms/step - loss: 0.0814 - val_loss: 0.0810\n",
      "Epoch 66/100\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 0.0813 - val_loss: 0.0810\n",
      "Epoch 67/100\n",
      "235/235 [==============================] - 3s 15ms/step - loss: 0.0811 - val_loss: 0.0807\n",
      "Epoch 68/100\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.0810 - val_loss: 0.0809\n",
      "Epoch 69/100\n",
      "235/235 [==============================] - 3s 15ms/step - loss: 0.0809 - val_loss: 0.0805\n",
      "Epoch 70/100\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0808 - val_loss: 0.0806\n",
      "Epoch 71/100\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0807 - val_loss: 0.0805\n",
      "Epoch 72/100\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 0.0806 - val_loss: 0.0805\n",
      "Epoch 73/100\n",
      "235/235 [==============================] - 3s 15ms/step - loss: 0.0805 - val_loss: 0.0804\n",
      "Epoch 74/100\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0805 - val_loss: 0.0802\n",
      "Epoch 75/100\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 0.0804 - val_loss: 0.0801\n",
      "Epoch 76/100\n",
      "235/235 [==============================] - 4s 15ms/step - loss: 0.0804 - val_loss: 0.0803\n",
      "Epoch 77/100\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 0.0803 - val_loss: 0.0801\n",
      "Epoch 78/100\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0802 - val_loss: 0.0801\n",
      "Epoch 79/100\n",
      "235/235 [==============================] - 3s 15ms/step - loss: 0.0802 - val_loss: 0.0797\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 3s 15ms/step - loss: 0.0801 - val_loss: 0.0800\n",
      "Epoch 81/100\n",
      "235/235 [==============================] - 4s 15ms/step - loss: 0.0801 - val_loss: 0.0799\n",
      "Epoch 82/100\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0800 - val_loss: 0.0799\n",
      "Epoch 83/100\n",
      "235/235 [==============================] - 4s 15ms/step - loss: 0.0799 - val_loss: 0.0797\n",
      "Epoch 84/100\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0799 - val_loss: 0.0796\n",
      "Epoch 85/100\n",
      "235/235 [==============================] - 3s 15ms/step - loss: 0.0799 - val_loss: 0.0796\n",
      "Epoch 86/100\n",
      "235/235 [==============================] - 4s 15ms/step - loss: 0.0798 - val_loss: 0.0795\n",
      "Epoch 87/100\n",
      "235/235 [==============================] - 3s 15ms/step - loss: 0.0798 - val_loss: 0.0796\n",
      "Epoch 88/100\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0798 - val_loss: 0.0794\n",
      "Epoch 89/100\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0797 - val_loss: 0.0795\n",
      "Epoch 90/100\n",
      "235/235 [==============================] - 4s 15ms/step - loss: 0.0797 - val_loss: 0.0794\n",
      "Epoch 91/100\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.0796 - val_loss: 0.0794\n",
      "Epoch 92/100\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0796 - val_loss: 0.0796\n",
      "Epoch 93/100\n",
      "235/235 [==============================] - 3s 15ms/step - loss: 0.0796 - val_loss: 0.0794\n",
      "Epoch 94/100\n",
      "235/235 [==============================] - 4s 15ms/step - loss: 0.0795 - val_loss: 0.0795\n",
      "Epoch 95/100\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.0795 - val_loss: 0.0793\n",
      "Epoch 96/100\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 0.0794 - val_loss: 0.0792\n",
      "Epoch 97/100\n",
      "235/235 [==============================] - 4s 15ms/step - loss: 0.0794 - val_loss: 0.0793\n",
      "Epoch 98/100\n",
      "235/235 [==============================] - 4s 15ms/step - loss: 0.0794 - val_loss: 0.0794\n",
      "Epoch 99/100\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 0.0793 - val_loss: 0.0793\n",
      "Epoch 100/100\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 0.0793 - val_loss: 0.0791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x207d2707e48>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n",
    "\n",
    "# Predict the Autoencoder output from test images\n",
    "# x_decoded = autoencoder.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1f34b22",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11648/771645095.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Encode and decode some digits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Note that we take them from the *test* set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mencoded_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoded\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdecoded_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_imgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "# Encode and decode some digits\n",
    "# Note that we take them from the *test* set\n",
    "encoded_imgs = encoded.predict(x_test)\n",
    "decoded_imgs = decoded.predict(encoded_imgs)\n",
    "\n",
    "n = 10  # How many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668343e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
